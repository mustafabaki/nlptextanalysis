{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiBmthN6TBMJ"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_excel('turkish_topic_modelling.xlsx')\n",
        "#data = pd.read_csv('abcnews-date-text.csv', error_bad_lines=False);\n",
        "data_text = data[['Document']]\n",
        "data_text['index'] = data_text.index\n",
        "documents = data_text"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUPRN9_iWSGu",
        "outputId": "614f96f1-2802-49f9-e4c3-1300ffe43de3"
      },
      "source": [
        "print(len(documents))\n",
        "print(documents[:5])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "647809\n",
            "                                            Document  index\n",
            "0  NGC 5713 Başak takımyıldızı bölgesinde bulunan...      0\n",
            "1  Birçok katalogda sarmal gökada olarak sınıflan...      1\n",
            "2  Corina Casanova , İsviçre Federal Şansölyesidir .      2\n",
            "3  Casanova , İsviçre Federal Yüksek Mahkemesi es...      3\n",
            "4       Corina Casanova bir federal parlementerdir .      4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg9qxTgtWY_I",
        "outputId": "d8d5d29d-8341-4079-ad8f-e61b1171f345"
      },
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(2018)\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caJHSmvWWaBY"
      },
      "source": [
        "\"\"\"!pip install -q wordcloud\n",
        "!pip install nltk\n",
        "import wordcloud\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') \"\"\"\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import unicodedata\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "#snow_stemmer = SnowballStemmer(language='english')\n",
        "from snowballstemmer import TurkishStemmer\n",
        "snow_stemmer=TurkishStemmer()\n",
        "\"\"\"from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "porter = PorterStemmer()\n",
        "lancaster=LancasterStemmer()\"\"\"\n",
        "def lemmatize_stemming(text):\n",
        "    return snow_stemmer.stemWord(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "    return result"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vItg2TfnWdQq",
        "outputId": "96b17ef6-1104-48c2-9127-ce041f454989"
      },
      "source": [
        "doc_sample = documents[documents['index'] == 4310].values[0][0]\n",
        "print('original document: ')\n",
        "words = []\n",
        "for word in doc_sample.split(' '):\n",
        "    words.append(word)\n",
        "print(words)\n",
        "print('\\n\\n tokenized and lemmatized document: ')\n",
        "preprocess(doc_sample)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original document: \n",
            "['Deri', 'yapısının', 'bozunabilirliği', 'kıllanımında', 'ciddi', 'problemlere', 'yol', 'açarken', 'kalıcı', 'dayanıklılık', 've', 'aynı', 'zamanda', 'kullanılabilirlik', 'sağlamada', 'temel', 'aşama', 'tabaklamadır', '.']\n",
            "\n",
            "\n",
            " tokenized and lemmatized document: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['der',\n",
              " 'yapı',\n",
              " 'bozunabilirlik',\n",
              " 'kıllanım',\n",
              " 'cidi',\n",
              " 'problem',\n",
              " 'açar',\n",
              " 'kalıç',\n",
              " 'dayanıklılık',\n",
              " 'aynı',\n",
              " 'zama',\n",
              " 'sağlama',\n",
              " 'temel',\n",
              " 'aşa',\n",
              " 'tabakla']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMLvxegy_VZ0",
        "outputId": "9779929d-b35e-4634-9b3f-9c8d8f70d4d2"
      },
      "source": [
        "processed_docs = documents['Document'].map(preprocess)\n",
        "processed_docs[:10]"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [başak, takımyıldız, bölge, buluna, tuhaf, asi...\n",
              "1    [birçok, katalogu, sarmal, göka, olarak, sınıf...\n",
              "2           [cor, casanov, sviçre, federal, şansölyes]\n",
              "3    [casanov, sviçre, federal, yük, mahkemes, eski...\n",
              "4                 [cor, casanov, federal, parlementer]\n",
              "5    [casanov, hristiya, demokrat, halk, partis, üy...\n",
              "6    [sviçre, dışiş, bakanlık, sviçre, federal, yön...\n",
              "7                 [sviçre, ilişki, sürdürmek, görevli]\n",
              "8    [gilgit, baltis, veya, pakis, kuzey, bölge, ur...\n",
              "9       [ala, kaplamak, oldukça, dağlık, arazi, sahip]\n",
              "Name: Document, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6_21OXOAOQP",
        "outputId": "b28bb6b2-2bfa-4f64-d3e1-3c381421395f"
      },
      "source": [
        "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 asimetrik\n",
            "1 başak\n",
            "2 buluna\n",
            "3 bölge\n",
            "4 göka\n",
            "5 takımyıldız\n",
            "6 tuhaf\n",
            "7 birçok\n",
            "8 farklı\n",
            "9 gökada\n",
            "10 katalogu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3gkxMyVAPoK"
      },
      "source": [
        "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCU6kpnYAUnU",
        "outputId": "6d1423e9-97d3-4431-931e-0add6a9d9cb9"
      },
      "source": [
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "bow_corpus[4310]"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(129, 1),\n",
              " (133, 1),\n",
              " (141, 1),\n",
              " (428, 1),\n",
              " (458, 1),\n",
              " (499, 1),\n",
              " (1969, 1),\n",
              " (2879, 1),\n",
              " (3281, 1),\n",
              " (3372, 1),\n",
              " (5020, 1),\n",
              " (7033, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owv2PB2-d-md",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19c1950e-6c01-4608-c3bb-2dba311e5120"
      },
      "source": [
        "bow_doc_4310 = bow_corpus[4310]\n",
        "for i in range(len(bow_doc_4310)):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
        "                                               dictionary[bow_doc_4310[i][0]], \n",
        "bow_doc_4310[i][1]))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word 129 (\"yapı\") appears 1 time.\n",
            "Word 133 (\"aynı\") appears 1 time.\n",
            "Word 141 (\"zama\") appears 1 time.\n",
            "Word 428 (\"dayanıklılık\") appears 1 time.\n",
            "Word 458 (\"temel\") appears 1 time.\n",
            "Word 499 (\"cidi\") appears 1 time.\n",
            "Word 1969 (\"der\") appears 1 time.\n",
            "Word 2879 (\"aşa\") appears 1 time.\n",
            "Word 3281 (\"kalıç\") appears 1 time.\n",
            "Word 3372 (\"açar\") appears 1 time.\n",
            "Word 5020 (\"sağlama\") appears 1 time.\n",
            "Word 7033 (\"problem\") appears 1 time.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gC9AU1JpAZOY",
        "outputId": "15dd09b8-4516-42ce-f2d9-8231dfc041d4"
      },
      "source": [
        "from gensim import corpora, models\n",
        "tfidf = models.TfidfModel(bow_corpus)\n",
        "corpus_tfidf = tfidf[bow_corpus]\n",
        "from pprint import pprint\n",
        "for doc in corpus_tfidf:\n",
        "    pprint(doc)\n",
        "    break"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0.5317289678349512),\n",
            " (1, 0.4553130927055291),\n",
            " (2, 0.20012217028669313),\n",
            " (3, 0.19410818121482892),\n",
            " (4, 0.3678576477058213),\n",
            " (5, 0.3373613792126616),\n",
            " (6, 0.427896569466722)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyN012AeAfmF"
      },
      "source": [
        "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHb7lzWSAgj_",
        "outputId": "de0d381d-a3ac-411b-e7a7-5d04c9209a3c"
      },
      "source": [
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "Words: 0.025*\"bölge\" + 0.019*\"ola\" + 0.019*\"bağlı\" + 0.018*\"merkez\" + 0.017*\"kuzey\" + 0.015*\"buluna\" + 0.015*\"ilçe\" + 0.014*\"güney\" + 0.014*\"eyalet\" + 0.014*\"il\"\n",
            "Topic: 1 \n",
            "Words: 0.023*\"sonra\" + 0.015*\"iç\" + 0.011*\"ola\" + 0.011*\"çocuk\" + 0.010*\"yaş\" + 0.010*\"kendi\" + 0.009*\"dah\" + 0.009*\"olduk\" + 0.007*\"kardeş\" + 0.007*\"oğlu\"\n",
            "Topic: 2 \n",
            "Words: 0.021*\"savaş\" + 0.012*\"yıl\" + 0.011*\"sonra\" + 0.010*\"taraf\" + 0.009*\"olarak\" + 0.009*\"karşı\" + 0.008*\"birlik\" + 0.008*\"iç\" + 0.008*\"alma\" + 0.008*\"osmanlı\"\n",
            "Topic: 3 \n",
            "Words: 0.046*\"yıl\" + 0.014*\"sonra\" + 0.012*\"olarak\" + 0.012*\"üniversites\" + 0.011*\"yap\" + 0.010*\"ol\" + 0.008*\"okul\" + 0.008*\"kadar\" + 0.008*\"al\" + 0.007*\"eğit\"\n",
            "Topic: 4 \n",
            "Words: 0.052*\"film\" + 0.019*\"yap\" + 0.015*\"filmi\" + 0.014*\"oy\" + 0.010*\"karakter\" + 0.008*\"televizyo\" + 0.008*\"sinema\" + 0.008*\"oyuncu\" + 0.008*\"ola\" + 0.007*\"adlı\"\n",
            "Topic: 5 \n",
            "Words: 0.024*\"tak\" + 0.022*\"futbol\" + 0.020*\"maç\" + 0.015*\"ol\" + 0.015*\"yıl\" + 0.014*\"ligi\" + 0.014*\"takım\" + 0.013*\"kupas\" + 0.013*\"sezo\" + 0.012*\"kulüp\"\n",
            "Topic: 6 \n",
            "Words: 0.024*\"iç\" + 0.024*\"olarak\" + 0.010*\"zama\" + 0.008*\"üzer\" + 0.008*\"dah\" + 0.007*\"olduk\" + 0.007*\"gip\" + 0.006*\"veya\" + 0.006*\"özellik\" + 0.006*\"gör\"\n",
            "Topic: 7 \n",
            "Words: 0.030*\"grup\" + 0.026*\"alp\" + 0.023*\"şarkı\" + 0.018*\"ödül\" + 0.018*\"yıl\" + 0.018*\"müzik\" + 0.015*\"taraf\" + 0.012*\"adlı\" + 0.011*\"yazar\" + 0.010*\"al\"\n",
            "Topic: 8 \n",
            "Words: 0.024*\"tarih\" + 0.016*\"olarak\" + 0.016*\"yıl\" + 0.015*\"türk\" + 0.012*\"başka\" + 0.009*\"taraf\" + 0.007*\"cumhuriyet\" + 0.007*\"devlet\" + 0.007*\"ara\" + 0.007*\"birlik\"\n",
            "Topic: 9 \n",
            "Words: 0.013*\"tür\" + 0.012*\"ola\" + 0.011*\"olduk\" + 0.011*\"gip\" + 0.010*\"olarak\" + 0.008*\"kitap\" + 0.007*\"dah\" + 0.007*\"iç\" + 0.006*\"eser\" + 0.006*\"orta\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDVq1SSgAi29",
        "outputId": "8d0216a0-7d70-4418-de46-4eb248dad4ce"
      },
      "source": [
        "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
        "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
        "    print('Topic: {} Word: {}'.format(idx, topic))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 Word: 0.004*\"olarak\" + 0.004*\"iç\" + 0.003*\"yıl\" + 0.003*\"ola\" + 0.003*\"üzer\" + 0.002*\"istatistik\" + 0.002*\"renk\" + 0.002*\"taraf\" + 0.002*\"büyük\" + 0.002*\"selçuklu\"\n",
            "Topic: 1 Word: 0.011*\"üniversites\" + 0.009*\"yıl\" + 0.005*\"schleswigi\" + 0.005*\"okul\" + 0.005*\"eğit\" + 0.005*\"holstein\" + 0.004*\"sonra\" + 0.004*\"ödül\" + 0.004*\"olarak\" + 0.004*\"mez\"\n",
            "Topic: 2 Word: 0.011*\"bölge\" + 0.011*\"il\" + 0.010*\"eyalet\" + 0.010*\"bağlı\" + 0.010*\"ilçe\" + 0.009*\"kuzey\" + 0.008*\"şehir\" + 0.008*\"merkez\" + 0.007*\"güney\" + 0.006*\"buluna\"\n",
            "Topic: 3 Word: 0.013*\"tak\" + 0.012*\"maç\" + 0.011*\"futbol\" + 0.009*\"ligi\" + 0.009*\"takım\" + 0.008*\"kupas\" + 0.008*\"yıl\" + 0.008*\"kulüp\" + 0.008*\"sezo\" + 0.007*\"ol\"\n",
            "Topic: 4 Word: 0.004*\"ola\" + 0.004*\"yıl\" + 0.004*\"taraf\" + 0.003*\"olarak\" + 0.003*\"vilayet\" + 0.003*\"oğlu\" + 0.003*\"sonra\" + 0.002*\"türk\" + 0.002*\"savaş\" + 0.002*\"kral\"\n",
            "Topic: 5 Word: 0.005*\"olarak\" + 0.005*\"iç\" + 0.004*\"japo\" + 0.004*\"eski\" + 0.004*\"gör\" + 0.003*\"olduk\" + 0.003*\"gip\" + 0.003*\"ola\" + 0.003*\"dah\" + 0.003*\"veya\"\n",
            "Topic: 6 Word: 0.005*\"iç\" + 0.004*\"olduk\" + 0.003*\"olarak\" + 0.003*\"kendi\" + 0.003*\"sonra\" + 0.003*\"ola\" + 0.003*\"dah\" + 0.002*\"turnuva\" + 0.002*\"çocuk\" + 0.002*\"baş\"\n",
            "Topic: 7 Word: 0.005*\"yıl\" + 0.003*\"şehrista\" + 0.003*\"olarak\" + 0.003*\"şirket\" + 0.003*\"ola\" + 0.003*\"nüfus\" + 0.003*\"alp\" + 0.003*\"taraf\" + 0.003*\"uçak\" + 0.003*\"kiş\"\n",
            "Topic: 8 Word: 0.009*\"savaş\" + 0.005*\"sonra\" + 0.004*\"yıl\" + 0.004*\"kuvvet\" + 0.004*\"et\" + 0.004*\"birlik\" + 0.004*\"osmanlı\" + 0.004*\"iç\" + 0.004*\"olarak\" + 0.003*\"karşı\"\n",
            "Topic: 9 Word: 0.015*\"film\" + 0.012*\"alp\" + 0.011*\"şarkı\" + 0.007*\"ödül\" + 0.007*\"müzik\" + 0.007*\"grup\" + 0.006*\"filmi\" + 0.006*\"yıl\" + 0.006*\"adlı\" + 0.006*\"yap\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xV-UXRLAkzB",
        "outputId": "c1823cec-1088-41f7-80e0-068016ac8ba7"
      },
      "source": [
        "processed_docs[4310]"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['der',\n",
              " 'yapı',\n",
              " 'bozunabilirlik',\n",
              " 'kıllanım',\n",
              " 'cidi',\n",
              " 'problem',\n",
              " 'açar',\n",
              " 'kalıç',\n",
              " 'dayanıklılık',\n",
              " 'aynı',\n",
              " 'zama',\n",
              " 'sağlama',\n",
              " 'temel',\n",
              " 'aşa',\n",
              " 'tabakla']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzK4fKKCAmtB",
        "outputId": "4a15e1e3-814f-4016-af7f-5c42cb2c2206"
      },
      "source": [
        "for index, score in sorted(lda_model[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
        "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Score: 0.6829941868782043\t \n",
            "Topic: 0.024*\"iç\" + 0.024*\"olarak\" + 0.010*\"zama\" + 0.008*\"üzer\" + 0.008*\"dah\" + 0.007*\"olduk\" + 0.007*\"gip\" + 0.006*\"veya\" + 0.006*\"özellik\" + 0.006*\"gör\"\n",
            "\n",
            "Score: 0.1689678281545639\t \n",
            "Topic: 0.023*\"sonra\" + 0.015*\"iç\" + 0.011*\"ola\" + 0.011*\"çocuk\" + 0.010*\"yaş\" + 0.010*\"kendi\" + 0.009*\"dah\" + 0.009*\"olduk\" + 0.007*\"kardeş\" + 0.007*\"oğlu\"\n",
            "\n",
            "Score: 0.09418332576751709\t \n",
            "Topic: 0.021*\"savaş\" + 0.012*\"yıl\" + 0.011*\"sonra\" + 0.010*\"taraf\" + 0.009*\"olarak\" + 0.009*\"karşı\" + 0.008*\"birlik\" + 0.008*\"iç\" + 0.008*\"alma\" + 0.008*\"osmanlı\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX3bPu04Aoln",
        "outputId": "425de7f9-a1b6-42e2-bfa5-c69bc8100e9d"
      },
      "source": [
        "for index, score in sorted(lda_model_tfidf[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
        "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Score: 0.8064629435539246\t \n",
            "Topic: 0.005*\"olarak\" + 0.005*\"iç\" + 0.004*\"japo\" + 0.004*\"eski\" + 0.004*\"gör\" + 0.003*\"olduk\" + 0.003*\"gip\" + 0.003*\"ola\" + 0.003*\"dah\" + 0.003*\"veya\"\n",
            "\n",
            "Score: 0.1319911628961563\t \n",
            "Topic: 0.005*\"iç\" + 0.004*\"olduk\" + 0.003*\"olarak\" + 0.003*\"kendi\" + 0.003*\"sonra\" + 0.003*\"ola\" + 0.003*\"dah\" + 0.002*\"turnuva\" + 0.002*\"çocuk\" + 0.002*\"baş\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "024KDCxDAqmm",
        "outputId": "a53de32c-a4d5-4dae-c9f2-4d021ae9116b"
      },
      "source": [
        "unseen_document = 'Joel bu durumu şöyle açıkladı : \" Amacımız daha çok , otelin John Goodman\\'ın oynadığı karakterin dışsallaştırılması görevini üstlenmesiydi . teri tıpkı duvar kağıdının soyulup '\n",
        "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
        "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.35681307315826416\t Topic: 0.023*\"sonra\" + 0.015*\"iç\" + 0.011*\"ola\" + 0.011*\"çocuk\" + 0.010*\"yaş\"\n",
            "Score: 0.22342631220817566\t Topic: 0.052*\"film\" + 0.019*\"yap\" + 0.015*\"filmi\" + 0.014*\"oy\" + 0.010*\"karakter\"\n",
            "Score: 0.22060909867286682\t Topic: 0.024*\"iç\" + 0.024*\"olarak\" + 0.010*\"zama\" + 0.008*\"üzer\" + 0.008*\"dah\"\n",
            "Score: 0.10388186573982239\t Topic: 0.021*\"savaş\" + 0.012*\"yıl\" + 0.011*\"sonra\" + 0.010*\"taraf\" + 0.009*\"olarak\"\n",
            "Score: 0.06748420745134354\t Topic: 0.025*\"bölge\" + 0.019*\"ola\" + 0.019*\"bağlı\" + 0.018*\"merkez\" + 0.017*\"kuzey\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6oCaO3aAsi5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}