{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmf_with_user_data_en.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvSxNXTCjbgI"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import re\n",
        "import string\n",
        "import snowballstemmer\n",
        "import spacy\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "\n",
        "#import user dataset\n",
        "path='/content/drive/MyDrive/True.csv' \n",
        "df = pd.read_csv(path)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPpzAwZE_8_d"
      },
      "source": [
        "column_name = 'text'\n",
        "content = df[column_name]"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOaEtlEJABSW"
      },
      "source": [
        "#Cleaning Process\n",
        "\n",
        "def clean_text(text):\n",
        "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)\n",
        "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
        "    return text\n",
        "\n",
        "stemmer = snowballstemmer.stemmer('english');\n",
        "\n",
        "def stemmer_fun(sentence):\n",
        "    token_words=word_tokenize(sentence)\n",
        "    stem_sentence=[]\n",
        "    for word in token_words:\n",
        "        stem_sentence.append(stemmer.stemWord(word))\n",
        "        stem_sentence.append(\" \") \n",
        "    return \"\".join(stem_sentence)\n",
        "\n",
        "i=0\n",
        "for text in content:\n",
        "  content[i]=clean_text(text)\n",
        "  i=i+1\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxZ5eKK0Lqb3"
      },
      "source": [
        "# Get N-number and Stopwords\n",
        "\n",
        "#user's stopwords \n",
        "stopwords = []\n",
        "a=False #if user does not give stopwords this variable = false\n",
        "if a: \n",
        "  #kullanıcıdan gelen stopwordsleri split ile ayırıp for döngüsünde append ile stopwords listesine ekliyoruz.\n",
        "  form=\"a,an,the,and,of,while,for,is,has,as,are,have,by,from,more,their\" #example\n",
        "  arr = form.split(',')\n",
        "  for i in arr:\n",
        "    stopwords.append(i)\n",
        "else:\n",
        "  sp = spacy.load('en_core_web_sm')\n",
        "  stopwords = sp.Defaults.stop_words\n",
        "\n",
        "\n",
        "#number of n\n",
        "min_n_gram = 2\n",
        "max_n_gram = 2 # user input"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mw2fDRa5pYd",
        "outputId": "6c68e5c5-0fb5-4c55-97dc-face6225060e"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "def stemmer_fun_stop(sentence,stopwords):\n",
        "    token_words=word_tokenize(sentence)\n",
        "    stem_sentence=[]\n",
        "    for word in token_words:\n",
        "      if word not in stopwords:\n",
        "        stem_sentence.append(word)\n",
        "        stem_sentence.append(\" \") \n",
        "    return \"\".join(stem_sentence)\n",
        "\n",
        "i=0\n",
        "for text in content:\n",
        "  content[i] = stemmer_fun_stop(text,stopwords)\n",
        "  i=i+1  \n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UENPnXjSRz0I",
        "outputId": "78537277-9ec7-4e12-9245-45a8671239bd"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "def lemma(sentence):\n",
        "  lem_content = []\n",
        "  sent = nltk.word_tokenize(sentence)\n",
        "  for w in sent:\n",
        "    word= lemmatizer.lemmatize(w, get_wordnet_pos(w))\n",
        "    lem_content.append(word)\n",
        "    lem_content.append(\" \") \n",
        "  return \"\".join(lem_content)\n",
        "\n",
        "i=0\n",
        "for text in content:\n",
        "  content[i] = lemma(text)\n",
        "  i=i+1  \n",
        "    \n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tXRgmjvDE8b"
      },
      "source": [
        "# NMF is able to use tf-idf\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=1000, ngram_range=(min_n_gram,max_n_gram)) \n",
        "tfidf = tfidf_vectorizer.fit_transform(content)\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
        "# Run NMF\n",
        "nmf = NMF(n_components=20, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbxaudKkmXsW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6321688c-d12b-4696-8d73-89cec349f590"
      },
      "source": [
        "# To display words with desc. order \n",
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print (\"Topic %d:\" % (topic_idx))\n",
        "        print (\" \".join([feature_names[i]\n",
        "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "        \n",
        "no_top_words = 10\n",
        "display_topics(nmf, tfidf_feature_names, no_top_words)        "
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 0:\n",
            "united state trump administration free trade executive order reuters united trade agreement north american enter united trade deal homeland security\n",
            "Topic 1:\n",
            "north korea north korean south korea south korean nuclear test ballistic missile nuclear weapon kim jong korea nuclear korean peninsula\n",
            "Topic 2:\n",
            "islamic state state militant deir alzor fight islamic air strike militant group shi ite syrian army iraqi force iraq syria\n",
            "Topic 3:\n",
            "prime minister london reuters european union minister theresa british prime reuters british northern ireland reuters britain conservative party told reporter\n",
            "Topic 4:\n",
            "white house house spokesman reuters white house official washington reuters house statement reuters president sean spicer josh earnest spokesman josh\n",
            "Topic 5:\n",
            "new york hillary clinton presidential candidate republican presidential donald trump york reuters democratic presidential presidential nominee presidential election nov election\n",
            "Topic 6:\n",
            "saudi arabia saad alhariri shi ite crown prince prince mohammed arab emirate united arab middle east mohammed bin beirut reuters\n",
            "Topic 7:\n",
            "supreme court high court appeal court court ruling court appeal low court court judge antonin scalia court nominee court decision\n",
            "Topic 8:\n",
            "united nation rakhine state security council rohingya muslim suu kyi security force ethnic cleanse un security myanmar military nation reuters\n",
            "Topic 9:\n",
            "house representative washington reuters tax reform republican senator paul ryan speaker paul senate republican tax cut told reporter health insurance\n",
            "Topic 10:\n",
            "moscow reuters vladimir putin news agency president vladimir reuters russian russian president agency report foreign minister reuters russia russian foreign\n",
            "Topic 11:\n",
            "angela merkel chancellor angela berlin reuters european union merkel conservative social democrat euro zone german chancellor reuters german emmanuel macron\n",
            "Topic 12:\n",
            "puerto rico hurricane irma mile km house representative york reuters reuters house federal government zika virus washington reuters paul ryan\n",
            "Topic 13:\n",
            "president barack barack obama climate change obama administration democratic president trump administration reuters president environmental protection presidentelect donald protection agency\n",
            "Topic 14:\n",
            "attorney general justice department trump campaign intelligence committee national security special counsel intelligence agency fbi director james comey director james\n",
            "Topic 15:\n",
            "state department secretary state rex tillerson state rex department official washington reuters reuters secretary department spokeswoman private email reuters united\n",
            "Topic 16:\n",
            "told reuters kill people official told people kill security force robert mugabe source told police officer vice president government official\n",
            "Topic 17:\n",
            "president donald donald trump reuters president washington reuters twitter account trump told trump administration executive order trump decision jerusalem israel\n",
            "Topic 18:\n",
            "beijing reuters communist party xi jinping president xi reuters china foreign ministry chinese president party congress china sea south china\n",
            "Topic 19:\n",
            "human right right group right watch geneva reuters right activist right abuse rodrigo duterte president rodrigo asylum seeker amnesty international\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RquLSv1DFts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee806a9f-3cf9-4538-86a7-6720b609b1ba"
      },
      "source": [
        "#Sample \n",
        "sample = \"\"\"\n",
        "  golf resorts lose a lot of money. According to a bombshell New York Times report published last year, the 15 courses he owns around the world have lost over $315 million over the past 20 years. The interesting question is why does Trump hang on to so many money-losing enterprises?\n",
        "Much about Trump's financial arrangements remains a mystery — partly because privately listed companies in the US can largely avoid public scrutiny — though investigations into whether Trump committed bank and tax fraud may reveal more.\n",
        "\"\"\" \n",
        "sample_clean = clean_text(sample)\n",
        "sample_lem = stemmer_fun_stop(sample_clean,stopwords)\n",
        "sample_all_clean = lemma(sample_lem)\n",
        "# Transform the TF-IDF\n",
        "test = tfidf_vectorizer.transform([sample_all_clean])\n",
        "#  Transform the TF-IDF: nmf_features\n",
        "nmf_features = nmf.transform(test)\n",
        " \n",
        " \n",
        "def display_topics_of_sample(model, feature_names, no_top_words, topic_names , prct):\n",
        "  y=29\n",
        "  for x in range(5):\n",
        "    topic_name = topic_names[0][y]\n",
        "    y = y-1  \n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "      if topic_name == topic_idx:\n",
        "        print (\"Topic percentage %\" , prct[0][topic_name])\n",
        "        print (\" \".join([feature_names[i]\n",
        "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "\n",
        "prct = nmf.transform(test)*100\n",
        "\n",
        "#make list\n",
        "def make_list(model, feature_names, no_top_words, topic_names , prct):\n",
        "    lst = []\n",
        "    y=19\n",
        "    for x in range(5):\n",
        "        topic_name = topic_names[0][y]\n",
        "        y = y-1  \n",
        "        for topic_idx, topic in enumerate(model.components_):\n",
        "            if topic_name == topic_idx:\n",
        "                lst.append( [prct[0][topic_name], \" \".join([feature_names[i]\n",
        "                                for i in topic.argsort()[:-no_top_words - 1:-1]])])\n",
        "    return lst\n",
        "    \n",
        "no_top_words=10\n",
        "prct = nmf.transform(test)*100\n",
        "List = make_list(nmf, tfidf_feature_names, no_top_words, nmf.transform(test).argsort(axis=1), prct)\n",
        "\n",
        "print(List)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.348042184274786, 'new york hillary clinton presidential candidate republican presidential donald trump york reuters democratic presidential presidential nominee presidential election nov election'], [0.033048243975657615, 'told reuters kill people official told people kill security force robert mugabe source told police officer vice president government official'], [0.01489786873881916, 'human right right group right watch geneva reuters right activist right abuse rodrigo duterte president rodrigo asylum seeker amnesty international'], [0.0, 'united nation rakhine state security council rohingya muslim suu kyi security force ethnic cleanse un security myanmar military nation reuters'], [0.0, 'north korea north korean south korea south korean nuclear test ballistic missile nuclear weapon kim jong korea nuclear korean peninsula']]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}