{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmf_with_user_data_tr.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAcLh4BlvLWt"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import re\n",
        "import string\n",
        "import snowballstemmer\n",
        "import spacy\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "\n",
        "#import user dataset\n",
        "path='/content/drive/MyDrive/18Gazete.csv' \n",
        "try:\n",
        "  df = pd.read_csv(path)\n",
        "except: \n",
        "  df = pd.read_csv(path, encoding = \"utf-16\")  "
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxMX78OpfZc1"
      },
      "source": [
        "column_name = 'HABERMETNI'\n",
        "content = df[column_name]"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "EHlj-kXil-4s",
        "outputId": "cfac3e19-3e72-4fd6-b76a-af4c1ae13453"
      },
      "source": [
        "content[0]"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Hentbol ligi aslında bu sezon pek çok zorluklar ile bir araya gelebildi. Fon üretilememesi, maliyetlerin artması, spor camiasından desteğin sınırlı alması, yönetim hataları nedeni ile iki yılda 57 kulüp hentboldan çekildi. Erkeklerde Selka gibi çok değerli bir yapı terk etti hentbolu. Batman ve Adıyaman Belediyeleri kapattı. Yozgat Bozok çıkmayı reddedip Başkent Akademi'ye devretti takımı. Bu kadar zorluklar ile uğraşan hentbol camiası, İstanbul Belediyesi'ne ait olan ve bulunduğu bölgede hentbol ölçülerine sahip tek tesisi, Ümraniye Haldun Alagaş Spor Salonu'nu da kaybetti.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiidPAeafZjL"
      },
      "source": [
        "#Cleaning Process\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "def clean_text(text):\n",
        "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)\n",
        "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
        "    return text\n",
        "\n",
        "i=0\n",
        "for text in content:\n",
        "  content[i]=clean_text(text)\n",
        "  i=i+1"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krTVIHubfZl8"
      },
      "source": [
        "# Get N-number and Stopwords\n",
        "stopwords_txt = \"acaba,ama,aslında,az,bazı,belki,biri,birkaç,birşey,biz,bu,çok,çünkü,da,daha,de,defa,diye,eğer,en,gibi,hem,hep,hepsi,her,hiç,için,ile,ise,kez,ki,kim,mı,mu,mü,nasıl,ne,neden,nerde,nerede,nereye,niçin,niye,o,sanki,şey,siz,şu,tüm,ve,veya,ya,yani\"\n",
        "initial_stopwords = stopwords_txt.split(\",\")\n",
        "\n",
        "#user's stopwords \n",
        "stopwords = []\n",
        "a=False #if user does not give stopwords this variable = false\n",
        "if a: \n",
        "  #kullanıcıdan gelen stopwordsleri split ile ayırıp for döngüsünde append ile stopwords listesine ekliyoruz.\n",
        "  form=\"bir,ben,sen,o,şu,bu\" #example\n",
        "  arr = form.split(',')\n",
        "  for i in arr:\n",
        "    stopwords.append(i)\n",
        "else:\n",
        "  for text in initial_stopwords:\n",
        "    stopwords.append(text)\n",
        "\n",
        "\n",
        "#number of n\n",
        "min_n_gram = 2\n",
        "max_n_gram = 2 # user input"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_SdFxfwfZoY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b9cc4b8-7f73-4f1f-fb97-b9acc6c52aa9"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "def stemmer_fun_stop(sentence,stopwords):\n",
        "    token_words=word_tokenize(sentence)\n",
        "    stem_sentence=[]\n",
        "    for word in token_words:\n",
        "      if word not in stopwords:\n",
        "        stem_sentence.append(word)\n",
        "        stem_sentence.append(\" \") \n",
        "    return \"\".join(stem_sentence)\n",
        "\n",
        "i=0\n",
        "for text in content:\n",
        "  content[i] = stemmer_fun_stop(text,stopwords)\n",
        "  i=i+1  "
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIjmvKZbfraM"
      },
      "source": [
        "#!pip install zeyrek\n",
        "import zeyrek\n",
        "import nltk\n",
        "analyzer = zeyrek.MorphAnalyzer()\n",
        "\n",
        "def lemmatization(texts, allowed_postags=[\"Noun\", 'Adj', 'Verb', 'Adv']):\n",
        "      texts_out = []\n",
        "      text = texts.split(\" \")\n",
        "      for sent in text:\n",
        "        if sent !=\"\":\n",
        "          x=analyzer.analyze(sent)[0][0]\n",
        "          if (x.pos==\"Unk\"):\n",
        "            texts_out.append(analyzer.lemmatize(sent)[0][1][0])\n",
        "          else:\n",
        "            texts_out.append(x.lemma)\n",
        "      return texts_out\n",
        "\n",
        "data_lemmatized=[]\n",
        "for text in content:\n",
        "  data_lemmatized.append(lemmatization(text, allowed_postags=['Noun', 'Adj', 'Verb', 'Adv']))\n",
        "\n",
        "\n"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT_dTUTyD9OV"
      },
      "source": [
        "data = []\n",
        "def combine(txt):\n",
        "  temp = []\n",
        "  for word in txt:\n",
        "    temp.append(word)\n",
        "    temp.append(\" \")\n",
        "  return \"\".join(temp)\n",
        "\n",
        "for txt in data_lemmatized:\n",
        "  data.append(combine(txt)) "
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJnLJtpkGLov"
      },
      "source": [
        "# NMF is able to use tf-idf\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=1000, ngram_range=(min_n_gram,max_n_gram)) \n",
        "tfidf = tfidf_vectorizer.fit_transform(data)\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
        "# Run NMF\n",
        "nmf = NMF(n_components=20, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43M39I2Ifv8X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf250bf-3e15-46d7-b5e6-b435e19dbd06"
      },
      "source": [
        "# To display words with desc. order \n",
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print (\"Topic %d:\" % (topic_idx))\n",
        "        print (\" \".join([feature_names[i]\n",
        "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "        \n",
        "no_top_words = 10\n",
        "display_topics(nmf, tfidf_feature_names, no_top_words)     "
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 0:\n",
            "flâş haber dakika flâş son dakika terör örgüt suri sınır ilçe bir serbest bırakmak mahkeme tutuk park hal iki kişi\n",
            "Topic 1:\n",
            "ak parti parti sözcü ömer çelik sözcü ömer faruk çelik cumhurbaşkanı ak devam etmek açıklama bulunmak parti genel tartışmak ilgili\n",
            "Topic 2:\n",
            "avrupa lig uefa avrupa lig grup hafta maç grup ikinci ikinci hafta grup hafta şampiyon lig beşiktaş uefa borussia mönchengladbach\n",
            "Topic 3:\n",
            "savunmak bakan millî savunmak bakan hulusi hulusi akmak güven bölge abd savunmak akmak abd bakan akmak bölge tesis mark esper\n",
            "Topic 4:\n",
            "yazı sozcucomtrde gün yüz şüphe tutuk gerekmek kendi genel başkan genel kurul genel müdür genel sekreter genelkurmay başkan getirmek toplam\n",
            "Topic 5:\n",
            "hayat kaybetmek kişi hayat kişi yaralamak kaybetmek kişi sonuç kişi dünya savaş paris emniyet form giymek savaş kalmak asker yaralamak\n",
            "Topic 6:\n",
            "son dakika dakika haber haber göre orta çıkmak son durum yılmak önce haber stanbul fatih ter miss turkey hava etki\n",
            "Topic 7:\n",
            "suudi arabistan cemal kaşık gazete cemal kaşık cinayet cemal kaşıkçın stanbul başkonsolos bir yılmak ileri sürmek suudi gazete bir devlet\n",
            "Topic 8:\n",
            "etki hal hal getirmek pkk terörist terörist etki hava harekât düzenlemek hava irakın kuzey bölge düzenlemek pençe harekât harekât pkk\n",
            "Topic 9:\n",
            "genel başkan chp genel kemal kılıçdaroğlu başkan kemal başkan yardımcı parti genel yi parti grup toplantı mhp genel saadet parti\n",
            "Topic 10:\n",
            "beledi başkan büyükşehir beledi başkan yardımcı yardımcı zeynep bursa gemlik zeynep akmak rehin alınmak gemlik ilçe mansur yavaş stanbul büyükşehir\n",
            "Topic 11:\n",
            "sosyal medya medya hesap medya üzer türki cumhuriyet medya platform yapmak paylaşım hakaret etmek hesap yapmak perde ev yapılanmak açıklama\n",
            "Topic 12:\n",
            "gözaltı alınmak elemek geçirildi düzenlemek operasyon şüphe gözaltı kişi gözaltı şube müdür mücadele şube suç mücadele müdür ekip yönelik operasyon\n",
            "Topic 13:\n",
            "tayyip erdoğan recep tayyip cumhurbaşkanı recep erdoğan başkan yüksek stişare stişare kurul kabul etmek bilal erdoğan erdoğan oğul cumhurbaşkanı tayyip\n",
            "Topic 14:\n",
            "meydan gelen büyük deprem deprem ardından geçen hafta gelen büyük hafta meydan silivri açık gelen deprem açık geçen veteriner fakülte\n",
            "Topic 15:\n",
            "hükümet karşıt karşıt gösteri başkent bağdat sokak çıkma çıkma yasak irakın başkent yasak ilân ilân edildi gösteri nedeniyle güvenlik güç\n",
            "Topic 16:\n",
            "prof dr meme kanser cinsel saldırı bir şey bir deprem ilişkin açıklama öğreti üye açıklama bulunmak bulunmak iddia büyük deprem\n",
            "Topic 17:\n",
            "teknik direktör fatih ter futbol federasyon ceza vermek yeni bir borussia mönchengladbach şampiyon lig uefa şampiyon hazırlık yapmak grup hafta\n",
            "Topic 18:\n",
            "süreyya önder sır süreyya terör örgüt anayasa mahkeme ifade özgürlük önder ifade karmak vermek milletvekili sır ihlâl edildiğine hdp ankara\n",
            "Topic 19:\n",
            "avrupa birlik birlik ab gümrük vergi vergi uygulamak ab komisyon abd avrupa başkan jeanclaude jeanclaude juncker komisyon başkan yasmak dış\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m-syE7Rfxz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98d961a2-2c1c-4bc8-884d-d76497acb1b7"
      },
      "source": [
        "#Sample \n",
        "sample = \"\"\" \n",
        "  operasyon gözaltı alınmak gözaltı alınmak şüphe elemek uyuşturmak geçirildi elemek geçirildi düzenl\n",
        "\"\"\"\n",
        "\n",
        "sample_clean = clean_text(sample)\n",
        "sample_lem = stemmer_fun_stop(sample_clean,stopwords)\n",
        "sample_all_clean = lemmatization(sample_lem, allowed_postags=['Noun', 'Adj', 'Verb', 'Adv'])\n",
        "sample_all_clean = combine(sample_all_clean)\n",
        "\n",
        "# Transform the TF-IDF\n",
        "test = tfidf_vectorizer.transform([sample_all_clean])\n",
        "#  Transform the TF-IDF: nmf_features\n",
        "nmf_features = nmf.transform(test)\n",
        " \n",
        " \n",
        "def display_topics_of_sample(model, feature_names, no_top_words, topic_names , prct):\n",
        "  y=19\n",
        "  for x in range(5):\n",
        "    topic_name = topic_names[0][y]\n",
        "    y = y-1  \n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "      if topic_name == topic_idx:\n",
        "        print (\"Topic percentage %\" , prct[0][topic_name])\n",
        "        print (\" \".join([feature_names[i]\n",
        "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "\n",
        "prct = nmf.transform(test)*100\n",
        "\n",
        "#make list\n",
        "def make_list(model, feature_names, no_top_words, topic_names , prct):\n",
        "    lst = []\n",
        "    y=19\n",
        "    for x in range(5):\n",
        "        topic_name = topic_names[0][y]\n",
        "        y = y-1  \n",
        "        for topic_idx, topic in enumerate(model.components_):\n",
        "            if topic_name == topic_idx:\n",
        "                lst.append( [prct[0][topic_name], \" \".join([feature_names[i]\n",
        "                                for i in topic.argsort()[:-no_top_words - 1:-1]])])\n",
        "    return lst\n",
        "    \n",
        "no_top_words=10\n",
        "prct = nmf.transform(test)*100\n",
        "List = make_list(nmf, tfidf_feature_names, no_top_words, nmf.transform(test).argsort(axis=1), prct)\n",
        "\n",
        "print(List)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[28.736822218349424, 'gözaltı alınmak elemek geçirildi düzenlemek operasyon şüphe gözaltı kişi gözaltı şube müdür mücadele şube suç mücadele müdür ekip yönelik operasyon'], [0.0, 'avrupa birlik birlik ab gümrük vergi vergi uygulamak ab komisyon abd avrupa başkan jeanclaude jeanclaude juncker komisyon başkan yasmak dış'], [0.0, 'etki hal hal getirmek pkk terörist terörist etki hava harekât düzenlemek hava irakın kuzey bölge düzenlemek pençe harekât harekât pkk'], [0.0, 'ak parti parti sözcü ömer çelik sözcü ömer faruk çelik cumhurbaşkanı ak devam etmek açıklama bulunmak parti genel tartışmak ilgili'], [0.0, 'avrupa lig uefa avrupa lig grup hafta maç grup ikinci ikinci hafta grup hafta şampiyon lig beşiktaş uefa borussia mönchengladbach']]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}