# -*- coding: utf-8 -*-
"""nmf_fast.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OwSYcDVUm-QI9Euat9O00KtHst_QL_v1
"""

"""This class is an auxilary class to pass the results to web app. """
class result:
    def __init__(self, topic, score):
        self.topic = topic
        self.score = score


def nmf_algorithm(thetext):
  from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
  from sklearn.decomposition import NMF
  import pandas as pd
  import joblib
  pd.set_option('display.max_columns', None)  
  pd.set_option('display.max_colwidth', None)
  #import data
  df = pd.read_csv('Algorithm/NMF/NMF_clean_data.csv')

  content = df['0']


  import joblib
  from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
  nmf = joblib.load('Algorithm/NMF/finalized_model.sav')

  # clean the data
  #!python -m spacy download en_core_web_sm #run just ones to install en_core_web_sm, if you don't have it
  import spacy
  import re
  import string
  def clean_text(text):
      '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''
      text = text.lower()
      text = re.sub(r'\[.*?\]', '', text)
      text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)
      text = re.sub(r'\w*\d\w*', '', text)
      return text

  nlp = spacy.load("en_core_web_sm")
  def lemmatizer(text):        
      sent = []
      doc = nlp(text)
      for word in doc:
          sent.append(word.lemma_)
      return " ".join(sent)


  # To display words with desc. order 
  def display_topics(model, feature_names, no_top_words):
      for topic_idx, topic in enumerate(model.components_):
          print ("Topic %d:" % (topic_idx))
          print (" ".join([feature_names[i]
                          for i in topic.argsort()[:-no_top_words - 1:-1]]))
          
  no_top_words = 10
  #display_topics(nmf, tfidf_feature_names, no_top_words)
  # NMF is able to use tf-idf
  tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=1000, stop_words='english')
  # tfidf = tfidf_vectorizer.fit_transform(df_clean)
  tfidf = tfidf_vectorizer.fit_transform(content)
  tfidf_feature_names = joblib.load('Algorithm/NMF/tfidf_feature_names.sav')

  import pandas as pd

  #Sample 
  sample = thetext
  sample_clean = clean_text(sample)
  sample_lem = lemmatizer(sample_clean)
  sample_all_clean = sample_lem.replace('-PRON-', '')

  # Transform the TF-IDF
  test = tfidf_vectorizer.transform([sample_all_clean])
  #  Transform the TF-IDF: nmf_features
  nmf_features = nmf.transform(test)
  

  def display_topic_of_sample(model, feature_names, no_top_words, topic_name):
      for topic_idx, topic in enumerate(model.components_):
        if topic_name==topic_idx:
          print ("Topic %d:" % (topic_idx))
          print (" ".join([feature_names[i]
                          for i in topic.argsort()[:-no_top_words - 1:-1]]))

  #display_topic_of_sample(nmf, tfidf_feature_names, no_top_words, nmf.transform(test).argmax(axis=1))


  def display_topics_of_sample(model, feature_names, no_top_words, topic_names , prct):
    y=29
    for x in range(5):
      topic_name = topic_names[0][y]
      y = y-1  
      for topic_idx, topic in enumerate(model.components_):
        if topic_name == topic_idx:
          print ("Topic percentage %" , prct[0][topic_name])
          print (" ".join([feature_names[i]
                          for i in topic.argsort()[:-no_top_words - 1:-1]]))

  prct = nmf.transform(test)*100
  #display_topics_of_sample(nmf, tfidf_feature_names, no_top_words, nmf.transform(test).argsort(axis=1), prct)


  #make list
  def make_list(model, feature_names, no_top_words, topic_names , prct):
      lst = []
      y=29
      for x in range(5):
          topic_name = topic_names[0][y]
          y = y-1  
          for topic_idx, topic in enumerate(model.components_):
              if topic_name == topic_idx:
                  lst.append( [prct[0][topic_name], " ".join([feature_names[i]
                                  for i in topic.argsort()[:-no_top_words - 1:-1]])])
      return lst
  prct = nmf.transform(test)*100
  List = make_list(nmf, tfidf_feature_names, no_top_words, nmf.transform(test).argsort(axis=1), prct)

  rslt = []
  print(List)
  print(len(List))
  for index in range(len(List)):
    theresult = result(List[index][1], List[index][0])
    rslt.append(theresult)
  
  return rslt
    





